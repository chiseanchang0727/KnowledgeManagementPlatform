epoch,step,train_loss
0,16,34371472.0
1,33,34364332.0
2,50,34354528.0
3,67,34340268.0
4,84,34319976.0
5,101,34292232.0
6,118,34255472.0
7,135,34208116.0
8,152,34148580.0
9,169,34075084.0
10,186,33986284.0
11,203,33880708.0
12,220,33756516.0
13,237,33612328.0
14,254,33446688.0
15,271,33258158.0
16,288,33045378.0
17,305,32806664.0
18,322,32541358.0
19,339,32248516.0
20,356,31927054.0
21,373,31576220.0
22,390,31196088.0
23,407,30786062.0
24,424,30345548.0
25,441,29875166.0
26,458,29375316.0
27,475,28846382.0
28,492,28288328.0
29,509,27701256.0
30,526,27085718.0
31,543,26443068.0
32,560,25774162.0
33,577,25081318.0
34,594,24365342.0
35,611,23627058.0
36,628,22870182.0
37,645,22097750.0
38,662,21309750.0
39,679,20509202.0
40,696,19697280.0
41,713,18877380.0
42,730,18051984.0
43,747,17224240.0
44,764,16396296.0
45,781,15571801.0
46,798,14751004.0
47,815,13939217.0
48,832,13137454.0
49,849,12349331.0
50,866,11576618.0
51,883,10824637.0
52,900,10094034.0
53,917,9386612.0
54,934,8705167.0
55,951,8049306.5
56,968,7423223.0
57,985,6826166.0
58,1002,6259855.0
59,1019,5724018.0
60,1036,5219601.0
61,1053,4746790.5
62,1070,4306601.0
63,1087,3897859.25
64,1104,3521256.75
65,1121,3175841.0
66,1138,2860179.25
67,1155,2575793.75
68,1172,2316100.5
69,1189,2084180.125
70,1206,1877609.375
71,1223,1692698.75
72,1240,1532102.5
73,1257,1390321.875
74,1274,1261688.25
75,1291,1152412.75
76,1308,1057467.5
77,1325,975152.875
78,1342,905015.5
79,1359,843712.5
80,1376,790046.75
81,1393,746520.625
82,1410,708378.125
83,1427,671931.375
84,1444,644266.9375
85,1461,619961.0
86,1478,599059.3125
87,1495,581787.5625
88,1512,567318.1875
89,1529,554871.375
90,1546,543989.75
91,1563,534576.875
92,1580,526638.8125
93,1597,519406.15625
94,1614,513292.0
95,1631,507719.15625
96,1648,503060.5625
97,1665,498449.125
98,1682,494524.40625
99,1699,490912.40625
