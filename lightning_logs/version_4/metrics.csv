epoch,step,train_loss
0,17,34344388.0
1,35,34336924.0
2,53,34326972.0
3,71,34312092.0
4,89,34290128.0
5,107,34259208.0
6,125,34217572.0
7,143,34163432.0
8,161,34094964.0
9,179,34010264.0
10,197,33907320.0
11,215,33784244.0
12,233,33639028.0
13,251,33469954.0
14,269,33275318.0
15,287,33053694.0
16,305,32803668.0
17,323,32523892.0
18,341,32212656.0
19,359,31869216.0
20,377,31493044.0
21,395,31083488.0
22,413,30639604.0
23,431,30161616.0
24,449,29649620.0
25,467,29104318.0
26,485,28525222.0
27,503,27912974.0
28,521,27266464.0
29,539,26590180.0
30,557,25881752.0
31,575,25147362.0
32,593,24387688.0
33,611,23603522.0
34,629,22796682.0
35,647,21969760.0
36,665,21126338.0
37,683,20268506.0
38,701,19400702.0
39,719,18524880.0
40,737,17644980.0
41,755,16763870.0
42,773,15885337.0
43,791,15011656.0
44,809,14146286.0
45,827,13292368.0
46,845,12452176.0
47,863,11629021.0
48,881,10826242.0
49,899,10048521.0
50,917,9296917.0
51,935,8573733.0
52,953,7880855.0
53,971,7221481.0
54,989,6594377.5
55,1007,6003718.5
56,1025,5449017.5
57,1043,4930243.0
58,1061,4448480.5
59,1079,4003168.0
60,1097,3594020.25
61,1115,3220447.75
62,1133,2879987.25
63,1151,2572340.5
64,1169,2296347.25
65,1187,2049839.875
66,1205,1831085.0
67,1223,1638701.875
68,1241,1470606.875
69,1259,1324003.25
70,1277,1196809.125
71,1295,1086829.25
72,1313,991901.8125
73,1331,910926.3125
74,1349,841779.4375
75,1367,782976.125
76,1385,732997.4375
77,1403,690819.9375
78,1421,655139.0
79,1439,624903.1875
80,1457,598854.25
81,1475,577252.0625
82,1493,558457.875
83,1511,542659.4375
84,1529,529235.25
85,1547,517985.28125
86,1565,508604.78125
87,1583,500038.375
88,1601,492938.75
89,1619,487054.3125
90,1637,481601.4375
91,1655,476272.6875
92,1673,472348.1875
93,1691,468192.5625
94,1709,464716.375
95,1727,461408.3125
96,1745,458175.875
97,1763,455159.0
98,1781,452276.21875
99,1799,449667.90625
