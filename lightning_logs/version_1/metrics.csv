epoch,step,train_loss
0,15,34162660.0
1,31,34157440.0
2,47,34150272.0
3,63,34139656.0
4,79,34124244.0
5,95,34102684.0
6,111,34073596.0
7,127,34035860.0
8,143,33988236.0
9,159,33929392.0
10,175,33858168.0
11,191,33773124.0
12,207,33672712.0
13,223,33555652.0
14,239,33420910.0
15,255,33267132.0
16,271,33092454.0
17,287,32896070.0
18,303,32677282.0
19,319,32435400.0
20,335,32169274.0
21,351,31878572.0
22,367,31561634.0
23,383,31217800.0
24,399,30847470.0
25,415,30450576.0
26,431,30027104.0
27,447,29577536.0
28,463,29101366.0
29,479,28598656.0
30,495,28069902.0
31,511,27514754.0
32,527,26934616.0
33,543,26330882.0
34,559,25704794.0
35,575,25057594.0
36,591,24390568.0
37,607,23704792.0
38,623,23001950.0
39,639,22282576.0
40,655,21547888.0
41,671,20798844.0
42,687,20037862.0
43,703,19268148.0
44,719,18492856.0
45,735,17715130.0
46,751,16936150.0
47,767,16158924.0
48,783,15385409.0
49,799,14618039.0
50,815,13857699.0
51,831,13108424.0
52,847,12369880.0
53,863,11647038.0
54,879,10939162.0
55,895,10249789.0
56,911,9579562.0
57,927,8931208.0
58,943,8304492.0
59,959,7700365.5
60,975,7123203.5
61,991,6573622.5
62,1007,6051999.5
63,1023,5557355.5
64,1039,5091213.5
65,1055,4654240.0
66,1071,4247558.5
67,1087,3870445.0
68,1103,3521712.0
69,1119,3200544.5
70,1135,2905522.75
71,1151,2636625.75
72,1167,2391903.25
73,1183,2171435.25
74,1199,1972959.875
75,1215,1795137.125
76,1231,1636459.25
77,1247,1495360.5
78,1263,1370391.125
79,1279,1259758.125
80,1295,1161985.25
81,1311,1076451.5
82,1327,1002002.875
83,1343,937384.5625
84,1359,881267.5
85,1375,832579.625
86,1391,790467.875
87,1407,753638.75
88,1423,721922.75
89,1439,694470.75
90,1455,670395.25
91,1471,649147.1875
92,1487,630654.0
93,1503,614131.5625
94,1519,600185.6875
95,1535,587597.0625
96,1551,576791.25
97,1567,566959.5625
98,1583,558199.8125
99,1599,550533.1875
